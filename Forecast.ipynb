{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f414a06b",
   "metadata": {},
   "source": [
    "# Librerias y dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79b878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Estudiante\\Proyecto-bootcamp\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# Manejo de direcotrios\n",
    "import os\n",
    "# Manejo de archivos\n",
    "import imageio\n",
    "import tempfile\n",
    "\n",
    "# Manejo de fechas\n",
    "from datetime import datetime\n",
    "\n",
    "# Manejo y procesamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Graficos de resultados\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelo de prediccion\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Generacion de mapas\n",
    "import folium\n",
    "from folium.plugins import HeatMap, HeatMapWithTime, MarkerCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e93b8",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5dd3c6",
   "metadata": {},
   "source": [
    "## Preparativos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2631ce",
   "metadata": {},
   "source": [
    "### Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4515ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOS_PATH = r\"Datasets\\Datos_de_entrenamiento.csv\"\n",
    "DIR_PATH = r\"Datasets\\Directorio_municipios_procesado.csv\"\n",
    "OUTPUT_DIR = r\"Resultados prediccion Top 10\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Fecha limite de prediccion\n",
    "PRED_END = \"2025-12-31\"\n",
    "\n",
    "# Selección: si deseas entrenar todos los municipios pon None, si prefieres top_k por visitas totales pon un entero\n",
    "TOP_K = 10\n",
    "MIN_MONTHS_FOR_MODEL = 6 # mínimo meses de datos para entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49e53d",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27babcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prophet_df(df, municipio):\n",
    "    d = df[df['MUNICIPIO'] == municipio][['ds','VISITAS']].rename(columns={'VISITAS':'y'}).sort_values('ds')\n",
    "    # llenar meses faltantes para continuidad (freq = MS)\n",
    "    if d.empty:\n",
    "        return d\n",
    "    idx = pd.date_range(d['ds'].min(), d['ds'].max(), freq='MS')\n",
    "    d = d.set_index('ds').reindex(idx).rename_axis('ds').reset_index()\n",
    "    d['y'] = d['y'].fillna(0)\n",
    "    return d\n",
    "\n",
    "def train_and_forecast(df_ts, periods_months):\n",
    "    m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "    # añadir seasonality mensual si se quiere:\n",
    "    m.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "    m.fit(df_ts)\n",
    "    future = m.make_future_dataframe(periods=periods_months, freq='MS')\n",
    "    forecast = m.predict(future)\n",
    "    return m, forecast\n",
    "\n",
    "def months_between_dates(start, end):\n",
    "    s = pd.to_datetime(start)\n",
    "    e = pd.to_datetime(end)\n",
    "    return (e.year - s.year) * 12 + (e.month - s.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ea31f",
   "metadata": {},
   "source": [
    "## Carga y procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3e60d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de municipios seleccionados: 10\n",
      "Municipios seleccionados: ['PAIPA', 'VILLA DE LEYVA', 'DUITAMA', 'AQUITANIA', 'TUNJA', 'IZA', 'MONGUI', 'TOTA', 'NOBSA', 'SOGAMOSO']\n",
      "Último dato en: 2024-10-01 00:00:00\n",
      "Meses a predecir: 14\n"
     ]
    }
   ],
   "source": [
    "# Carga y preprocesamiento básico\n",
    "df_raw = pd.read_csv(DATOS_PATH)\n",
    "df_dir = pd.read_csv(DIR_PATH)\n",
    "\n",
    "\n",
    "# Esperamos: df_raw con MES,AÑO,MUNICIPIO,VISITAS\n",
    "# Crear columna fecha (usaremos primer día del mes)\n",
    "df_raw['MES'] = df_raw['MES'].astype(int)\n",
    "df_raw['AÑO'] = df_raw['AÑO'].astype(int)\n",
    "df_raw['ds'] = pd.to_datetime(df_raw['AÑO'].astype(str) + '-' + df_raw['MES'].astype(str).str.zfill(2) + '-01')\n",
    "\n",
    "\n",
    "# Merge para unir coordenadas (puede haber municipios sin coordenadas)\n",
    "df_merge = df_raw.merge(df_dir[['MUNICIPIO','LONGITUD','LATITUD']], on='MUNICIPIO', how='left')\n",
    "\n",
    "\n",
    "agg_total = df_merge.groupby('MUNICIPIO', as_index=False)['VISITAS'].sum().sort_values('VISITAS', ascending=False)\n",
    "if TOP_K is None:\n",
    "    lstMunicipios = agg_total['MUNICIPIO'].tolist()\n",
    "else:\n",
    "    lstMunicipios = agg_total.head(TOP_K)['MUNICIPIO'].tolist()\n",
    "\n",
    "print(f\"Cantidad de municipios seleccionados: {len(lstMunicipios)}\")\n",
    "print(f\"Municipios seleccionados: {lstMunicipios}\")\n",
    "\n",
    "\n",
    "# Preparar horizonte en meses desde último dato hasta PRED_END\n",
    "last_date = df_merge['ds'].max()\n",
    "print('Último dato en:', last_date)\n",
    "periods_to_predict = months_between_dates(last_date, PRED_END)\n",
    "print('Meses a predecir:', periods_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e9933",
   "metadata": {},
   "source": [
    "## Entrenamiento y Evaluacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293948a2",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82959c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:01:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:01:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:01:13 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para PAIPA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:01:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:01:34 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para VILLA DE LEYVA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:01:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:01:48 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para DUITAMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:01:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:01:49 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para AQUITANIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:01:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:02:00 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para TUNJA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:02:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:02:13 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para IZA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:02:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:02:32 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para MONGUI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:02:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:02:47 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para TOTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:03:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "19:03:01 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para NOBSA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:03:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SOGAMOSO\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for municipio in lstMunicipios:\n",
    "    df_ts = prepare_prophet_df(df_merge, municipio)\n",
    "    if df_ts.shape[0] < MIN_MONTHS_FOR_MODEL:\n",
    "        print(f\"Omitido {municipio}: solo {df_ts.shape[0]} meses de datos\")\n",
    "        continue\n",
    "    try:\n",
    "        model, forecast = train_and_forecast(df_ts, periods_to_predict)\n",
    "        results[municipio] = {'model': model, 'forecast': forecast, 'history': df_ts}\n",
    "        # Guardar gráfica simple\n",
    "        fig = model.plot(forecast)\n",
    "        path = os.path.join(OUTPUT_DIR, municipio)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        fig.savefig(os.path.join(path, f'forecast.png'), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        comp = model.plot_components(forecast)\n",
    "        comp.savefig(os.path.join(OUTPUT_DIR, municipio, f'components.png'), bbox_inches='tight')\n",
    "        plt.close(comp)\n",
    "        print(f\"Modelo generado para {municipio}\")\n",
    "    except Exception as e:\n",
    "        print('Error en ', municipio, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531eef0b",
   "metadata": {},
   "source": [
    "### Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2103a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación MAPE(Mean Absolute Percentage Error) que significa Error Porcentual Absoluto Medio.\n",
    "#  sobre el período observado usando los puntos de backtest en forecast\n",
    "\n",
    "evals = []\n",
    "for muni, obj in results.items():\n",
    "    hist = obj['history']\n",
    "    f = obj['forecast']\n",
    "    # tomar solo las fechas que estaban en el histórico\n",
    "    f_obs = f[f['ds'].isin(hist['ds'])]\n",
    "    if f_obs.empty:\n",
    "        continue\n",
    "    y_true = hist['y'].values\n",
    "    y_pred = f_obs['yhat'].values\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    evals.append({'MUNICIPIO': muni, 'MAPE': mape})\n",
    "\n",
    "\n",
    "pd.DataFrame(evals).sort_values('MAPE').to_csv(os.path.join(OUTPUT_DIR, 'evaluation_mape.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b490c04",
   "metadata": {},
   "source": [
    "# Visualizacion de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82123cf",
   "metadata": {},
   "source": [
    "\n",
    "## Preparacion datos mensuales por municipio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b5e9a",
   "metadata": {},
   "source": [
    "## Estandarizacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1ddc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar data mensual por municipio para el mapa (unir histórico + predicción)\n",
    "# Vamos a construir una tabla con columnas: ds, MUNICIPIO, VISITAS (observado o predicho), LONGITUD, LATITUD\n",
    "map_rows = []\n",
    "for muni, obj in results.items():\n",
    "    f = obj['forecast'][['ds','yhat']].copy().rename(columns={'yhat':'VISITAS'})\n",
    "    last_hist = obj['history']['ds'].max()\n",
    "    f['TIPO'] = np.where(f['ds'] <= last_hist, 'OBS', 'PRED')\n",
    "    # adjuntar coordenadas\n",
    "    coords_df = df_dir[df_dir['MUNICIPIO']==muni][['LONGITUD','LATITUD']]\n",
    "    if not coords_df.empty:\n",
    "        coords = coords_df.iloc[0].to_dict()\n",
    "        f['LONGITUD'] = coords.get('LONGITUD', None)\n",
    "        f['LATITUD'] = coords.get('LATITUD', None)\n",
    "    else:\n",
    "        f['LONGITUD'] = np.nan\n",
    "        f['LATITUD'] = np.nan\n",
    "    f['MUNICIPIO'] = muni\n",
    "    map_rows.append(f)\n",
    "\n",
    "map_df = pd.concat(map_rows, ignore_index=True)\n",
    "\n",
    "# Filtrar filas sin coords\n",
    "map_df = map_df.dropna(subset=['LONGITUD','LATITUD'])\n",
    "\n",
    "max_global = map_df['VISITAS'].max()\n",
    "map_df['INTENSIDAD_FORZADA'] = map_df['VISITAS'] / (max_global if max_global > 0 else 1)\n",
    "map_df['INTENSIDAD_FORZADA'] = map_df['INTENSIDAD_FORZADA'].clip(lower=0.05)\n",
    "map_df['MES_STR'] = map_df['ds'].dt.strftime('%Y-%m')\n",
    "map_df['INTENSIDAD_MES_FORZADA'] = map_df.groupby('MES_STR')['VISITAS'].transform(\n",
    "    lambda x: (x / (x.max() if x.max() > 0 else 1)).clip(lower=0.05)\n",
    ")\n",
    "map_df.to_csv(os.path.join(OUTPUT_DIR, 'map_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0cfa4",
   "metadata": {},
   "source": [
    "## Visualizacion con mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d5c1fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapa guardado en: Resultados prediccion Top 10\\Mapa_de_calor.html\n"
     ]
    }
   ],
   "source": [
    "# Crear un mapa con HeatMapWithTime + MarkerCluster.\n",
    "# HeatMapWithTime espera una lista de matrices de [lat,lon,intensity]\n",
    "months = sorted(map_df['MES_STR'].unique())\n",
    "heat_data = []\n",
    "for m in months:\n",
    "    sub = map_df[map_df['MES_STR'] == m]\n",
    "    # HeatMap expects [lat, lon, weight]\n",
    "    heat_data.append(sub[['LATITUD','LONGITUD','INTENSIDAD_FORZADA']].values.tolist())\n",
    "\n",
    "# Calcular centro del mapa\n",
    "mid_lat = map_df['LATITUD'].mean()\n",
    "mid_lon = map_df['LONGITUD'].mean()\n",
    "# Crear mapa base\n",
    "m = folium.Map(location=[mid_lat, mid_lon], zoom_start=6)\n",
    "\n",
    "# Porpiedades mapa de calor\n",
    "HeatMapWithTime(\n",
    "    heat_data,\n",
    "    index=months,\n",
    "    radius=25,\n",
    "    auto_play=False,\n",
    "    max_opacity=0.8\n",
    ").add_to(m)\n",
    "\n",
    "# Organizacion de marcadores por clusters\n",
    "mc = MarkerCluster()\n",
    "for _, row in map_df[map_df['ds'] == map_df['ds'].min()].iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['LATITUD'], row['LONGITUD']],\n",
    "        popup=f\"{row['MUNICIPIO']}\"\n",
    "    ).add_to(mc)\n",
    "mc.add_to(m)\n",
    "\n",
    "# Guardar mapa HTML\n",
    "map_html_path = os.path.join(OUTPUT_DIR, 'Mapa_de_calor.html')\n",
    "m.save(map_html_path)\n",
    "print('Mapa guardado en:', map_html_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
