{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f414a06b",
   "metadata": {},
   "source": [
    "# Librerias y dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d79b878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "import folium\n",
    "from folium.plugins import HeatMap, HeatMapWithTime, MarkerCluster\n",
    "import imageio\n",
    "import tempfile\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e93b8",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5dd3c6",
   "metadata": {},
   "source": [
    "## Preparativos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2631ce",
   "metadata": {},
   "source": [
    "### Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOS_PATH = r\"Datasets\\Datos_de_entrenamiento.csv\"\n",
    "DIR_PATH = r\"Datasets\\Directorio_municipios_procesado.csv\"\n",
    "OUTPUT_DIR = r\"output_prophet_maps\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Horizon de predicción (hasta diciembre 2025)\n",
    "PRED_END = \"2025-12-31\"\n",
    "\n",
    "\n",
    "# Selección: si deseas entrenar todos los municipios pon None, si prefieres top_k por visitas totales pon un entero\n",
    "# TOP_K = 10\n",
    "TOP_K = None\n",
    "MIN_MONTHS_FOR_MODEL = 6 # mínimo meses de datos para entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49e53d",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27babcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prophet_df(df, municipio):\n",
    "    d = df[df['MUNICIPIO'] == municipio][['ds','VISITAS']].rename(columns={'VISITAS':'y'}).sort_values('ds')\n",
    "    # llenar meses faltantes para continuidad (freq = MS)\n",
    "    if d.empty:\n",
    "        return d\n",
    "    idx = pd.date_range(d['ds'].min(), d['ds'].max(), freq='MS')\n",
    "    d = d.set_index('ds').reindex(idx).rename_axis('ds').reset_index()\n",
    "    d['y'] = d['y'].fillna(0)\n",
    "    return d\n",
    "\n",
    "def train_and_forecast(df_ts, periods_months):\n",
    "    m = Prophet(yearly_seasonality=True, weekly_seasonality=False, daily_seasonality=False)\n",
    "    # añadir seasonality mensual si se quiere:\n",
    "    m.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "    m.fit(df_ts)\n",
    "    future = m.make_future_dataframe(periods=periods_months, freq='MS')\n",
    "    forecast = m.predict(future)\n",
    "    return m, forecast\n",
    "\n",
    "def months_between_dates(start, end):\n",
    "    s = pd.to_datetime(start)\n",
    "    e = pd.to_datetime(end)\n",
    "    return (e.year - s.year) * 12 + (e.month - s.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ea31f",
   "metadata": {},
   "source": [
    "## Carga y procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e60d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga y preprocesamiento básico\n",
    "df_raw = pd.read_csv(DATOS_PATH)\n",
    "df_dir = pd.read_csv(DIR_PATH)\n",
    "\n",
    "\n",
    "# Esperamos: df_raw con MES,AÑO,MUNICIPIO,VISITAS\n",
    "# Crear columna fecha (usaremos primer día del mes)\n",
    "df_raw['MES'] = df_raw['MES'].astype(int)\n",
    "df_raw['AÑO'] = df_raw['AÑO'].astype(int)\n",
    "df_raw['DIA'] = pd.to_datetime(df_raw['AÑO'].astype(str) + '-' + df_raw['MES'].astype(str).str.zfill(2) + '-01')\n",
    "\n",
    "\n",
    "# Merge para unir coordenadas (puede haber municipios sin coordenadas)\n",
    "df_merge = df_raw.merge(df_dir[['MUNICIPIO','LONGITUD','LATITUD']], on='MUNICIPIO', how='left')\n",
    "\n",
    "\n",
    "agg_total = df_merge.groupby('MUNICIPIO', as_index=False)['VISITAS'].sum().sort_values('VISITAS', ascending=False)\n",
    "if TOP_K is None:\n",
    "    lstMunicipios = agg_total['MUNICIPIO'].tolist()\n",
    "else:\n",
    "    lstMunicipios = agg_total.head(TOP_K)['MUNICIPIO'].tolist()\n",
    "\n",
    "print(f\"Cantidad de municipios seleccionados: {len(lstMunicipios)}\")\n",
    "print(f\"Municipios seleccionados: {lstMunicipios}\")\n",
    "\n",
    "\n",
    "\n",
    "# Preparar horizonte en meses desde último dato hasta PRED_END\n",
    "last_date = df_merge['DIA'].max()\n",
    "print('Último dato en:', last_date)\n",
    "periods_to_predict = months_between_dates(last_date, PRED_END)\n",
    "print('Meses a predecir:', periods_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85e9933",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82959c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:46:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:46:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:46:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:46:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:46:41 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para PAIPA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:46:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:46:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:46:52 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para VILLA DE LEYVA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:47:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:47:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:47:02 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para DUITAMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:47:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:47:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:47:03 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para AQUITANIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:47:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:47:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:47:10 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para TUNJA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:47:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:47:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:47:21 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para IZA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:47:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:47:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:47:31 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para MONGUI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:47:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:47:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:47:40 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para TOTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:47:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:47:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:47:50 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para NOBSA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:00 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SOGAMOSO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:11 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para TIBASOSA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:12 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para CUITIVA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:14 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para RAQUIRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:16 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:16 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para FIRAVITOBA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:19 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para CHIQUINQUIRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:20 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para VENTAQUEMADA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:30 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SACHICA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:41 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:41 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SUTAMARCHAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:51 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para MONIQUIRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:51 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:52 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para BOYACA\n",
      "Omitido GUATEQUE: solo 4 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:53 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para BELEN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:48:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:48:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:48:54 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SAMACA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:04 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para CERINZA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:13 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para CORRALES\n",
      "Omitido GARAGOA: solo 5 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:13 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:14 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para EL COCUY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:14 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:14 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para RAMIRIQUI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:15 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para COMBITA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:25 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:25 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SANTA SOFIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:26 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:27 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para PESCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:29 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para GUAYATA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:38 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para TUTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:39 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:39 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SANTA ROSA DE VITERBO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:41 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:42 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para ARCABUCO\n",
      "Omitido MACANAL: solo 4 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:42 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para MIRAFLORES\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:43 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:43 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para MONGUA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:44 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SOMONDOCO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:46 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:46 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para CUCAITA\n",
      "Omitido CHISCAS: solo 1 meses de datos\n",
      "Omitido CHIVOR: solo 4 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:54 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para ALMEIDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:54 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SOATA\n",
      "Omitido SANTA MARIA: solo 2 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:55 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para TOCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:58 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para PAJARITO\n",
      "Omitido SUTATENZA: solo 2 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:49:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:49:59 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para GAMEZA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:49:59 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:00 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para GUICAN\n",
      "Omitido TENZA: solo 2 meses de datos\n",
      "Omitido CHIQUIZA: solo 2 meses de datos\n",
      "Omitido EL ESPINO: solo 1 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:09 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para BETEITIVA\n",
      "Omitido FLORESTA: solo 5 meses de datos\n",
      "Omitido LA CAPILLA: solo 2 meses de datos\n",
      "Omitido SAN LUIS DE GACENO: solo 2 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:10 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para BUSBANZA\n",
      "Omitido CHITARAQUE: solo 4 meses de datos\n",
      "Omitido MARIPI: solo 1 meses de datos\n",
      "Omitido JENESANO: solo 5 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:11 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SABOYA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:12 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para PAZ DE RIO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:12 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:13 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para BOAVITA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:22 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para BERBEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:22 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SORACA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:23 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para TOPAGA\n",
      "Omitido CUBARA: solo 1 meses de datos\n",
      "Omitido CHITA: solo 1 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:23 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:24 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para CHINAVITA\n",
      "Omitido BRICENO: solo 1 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:24 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:24 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para SOTAQUIRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:33 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:33 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para PUERTO BOYACA\n",
      "Omitido PACHAVITA: solo 2 meses de datos\n",
      "Omitido UMBITA: solo 2 meses de datos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:34 - cmdstanpy - INFO - Chain [1] done processing\n",
      "22:50:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:50:34 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para ZETAQUIRA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:50:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo generado para TASCO\n",
      "Omitido TINJACA: solo 5 meses de datos\n",
      "Omitido TUNUNGUA: solo 3 meses de datos\n",
      "Omitido GUACAMAYAS: solo 1 meses de datos\n",
      "Omitido PAUNA: solo 1 meses de datos\n",
      "Omitido MUZO: solo 1 meses de datos\n",
      "Omitido LA UVITA: solo 1 meses de datos\n",
      "Omitido SAN EDUARDO: solo 1 meses de datos\n",
      "Omitido SAN JOSE DE PARE: solo 1 meses de datos\n",
      "Omitido SANTANA: solo 1 meses de datos\n",
      "Omitido SATIVANORTE: solo 1 meses de datos\n",
      "Omitido SUSACON: solo 1 meses de datos\n",
      "Omitido TIBANA: solo 1 meses de datos\n",
      "Omitido TOGUI: solo 1 meses de datos\n",
      "Omitido TUTAZA: solo 1 meses de datos\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for municipio in lstMunicipios:\n",
    "    df_ts = prepare_prophet_df(df_merge, municipio)\n",
    "    if df_ts.shape[0] < MIN_MONTHS_FOR_MODEL:\n",
    "        print(f\"Omitido {municipio}: solo {df_ts.shape[0]} meses de datos\")\n",
    "        continue\n",
    "    try:\n",
    "        model, forecast = train_and_forecast(df_ts, periods_to_predict)\n",
    "        results[municipio] = {'model': model, 'forecast': forecast, 'history': df_ts}\n",
    "        # Guardar gráfica simple\n",
    "        fig = model.plot(forecast)\n",
    "        fig.savefig(os.path.join(OUTPUT_DIR, municipio, f'forecast.png'), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        comp = model.plot_components(forecast)\n",
    "        comp.savefig(os.path.join(OUTPUT_DIR, f'components.png'), bbox_inches='tight')\n",
    "        plt.close(comp)\n",
    "        print(f\"Modelo generado para {municipio}\")\n",
    "    except Exception as e:\n",
    "        print('Error en ', municipio, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531eef0b",
   "metadata": {},
   "source": [
    "# Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2103a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación rápida (MAPE) sobre el período observado usando los puntos de backtest en forecast\n",
    "evals = []\n",
    "for muni, obj in results.items():\n",
    "    hist = obj['history']\n",
    "    f = obj['forecast']\n",
    "    # tomar solo las fechas que estaban en el histórico\n",
    "    f_obs = f[f['ds'].isin(hist['ds'])]\n",
    "    if f_obs.empty:\n",
    "        continue\n",
    "    y_true = hist['y'].values\n",
    "    y_pred = f_obs['yhat'].values\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    evals.append({'MUNICIPIO': muni, 'MAPE': mape})\n",
    "\n",
    "\n",
    "pd.DataFrame(evals).sort_values('MAPE').to_csv(os.path.join(OUTPUT_DIR, 'evaluation_mape.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82123cf",
   "metadata": {},
   "source": [
    "## -----------------------------\n",
    "## Preparacion datos mensuales por municipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1ddc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar data mensual por municipio para el mapa (unir histórico + predicción)\n",
    "# Vamos a construir una tabla con columnas: ds, MUNICIPIO, VISITAS (observado o predicho), LONGITUD, LATITUD\n",
    "map_rows = []\n",
    "for muni, obj in results.items():\n",
    "    f = obj['forecast'][['ds','yhat']].copy().rename(columns={'yhat':'VISITAS'})\n",
    "    # si quieres marcar qué es observado vs predicho:\n",
    "    last_hist = obj['history']['ds'].max()\n",
    "    f['TIPO'] = np.where(f['ds'] <= last_hist, 'OBS', 'PRED')\n",
    "    # adjuntar coordenadas\n",
    "    coords_df = df_dir[df_dir['MUNICIPIO']==muni][['LONGITUD','LATITUD']]\n",
    "    if not coords_df.empty:\n",
    "        coords = coords_df.iloc[0].to_dict()\n",
    "        f['LONGITUD'] = coords.get('LONGITUD', None)\n",
    "        f['LATITUD'] = coords.get('LATITUD', None)\n",
    "    else:\n",
    "        f['LONGITUD'] = np.nan\n",
    "        f['LATITUD'] = np.nan\n",
    "    f['MUNICIPIO'] = muni\n",
    "    map_rows.append(f)\n",
    "\n",
    "\n",
    "map_df = pd.concat(map_rows, ignore_index=True)\n",
    "# Filtrar filas sin coords\n",
    "map_df = map_df.dropna(subset=['LONGITUD','LATITUD'])\n",
    "\n",
    "\n",
    "# Normalizar intensidad por mes (opcional) para que colores sean comparables\n",
    "# Opción A: normalizar por valor máximo global\n",
    "max_global = map_df['VISITAS'].max()\n",
    "map_df['INTENSIDAD_GLOB'] = map_df['VISITAS'] / (max_global if max_global>0 else 1)\n",
    "# Opción B: normalizar por mes (si prefieres comparar distribución interna de cada mes)\n",
    "map_df['MES_STR'] = map_df['ds'].dt.strftime('%Y-%m')\n",
    "map_df['INTENSIDAD_MES'] = map_df.groupby('MES_STR')['VISITAS'].transform(lambda x: x / (x.max() if x.max()>0 else 1))\n",
    "\n",
    "\n",
    "map_df.to_csv(os.path.join(OUTPUT_DIR,'map_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0cfa4",
   "metadata": {},
   "source": [
    "## Visualizacion con mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d5c1fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapa con time saved en: output_prophet_maps\\heatmap_time.html\n"
     ]
    }
   ],
   "source": [
    "# Crear un mapa con HeatMapWithTime + MarkerCluster. HeatMapWithTime espera una lista de matrices de [lat,lon,intensity]\n",
    "# Preparar lista ordenada de meses\n",
    "months = sorted(map_df['MES_STR'].unique())\n",
    "heat_data = []\n",
    "for m in months:\n",
    "    sub = map_df[map_df['MES_STR']==m]\n",
    "    # HeatMap expects [lat, lon, weight]\n",
    "    heat_data.append(sub[['LATITUD','LONGITUD','INTENSIDAD_GLOB']].values.tolist())\n",
    "\n",
    "\n",
    "mid_lat = map_df['LATITUD'].mean()\n",
    "mid_lon = map_df['LONGITUD'].mean()\n",
    "\n",
    "\n",
    "m = folium.Map(location=[mid_lat, mid_lon], zoom_start=6)\n",
    "\n",
    "\n",
    "# HeatMapWithTime\n",
    "HeatMapWithTime(heat_data, index=months, auto_play=False, max_opacity=0.8).add_to(m)\n",
    "\n",
    "\n",
    "# MarkerCluster para mostrar puntos (puede saturar la vista si hay muchos)\n",
    "mc = MarkerCluster()\n",
    "for _, row in map_df[map_df['ds'] == map_df['ds'].min()].iterrows():\n",
    "    folium.Marker(location=[row['LATITUD'], row['LONGITUD']], popup=f\"{row['MUNICIPIO']}\").add_to(mc)\n",
    "mc.add_to(m)\n",
    "\n",
    "\n",
    "# Guardar mapa HTML\n",
    "map_html_path = os.path.join(OUTPUT_DIR, 'heatmap_time.html')\n",
    "m.save(map_html_path)\n",
    "print('Mapa con time saved en:', map_html_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29be90ac",
   "metadata": {},
   "source": [
    "## Generacion Gif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971a4c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar GIF: estrategia\n",
    "# 1) Crear snapshots de mapas por mes (renderizar HTML a PNG). Para ello puedes usar selenium + chromium headless.\n",
    "# 2) Convertir PNGs a GIF con imageio.\n",
    "\n",
    "\n",
    "# Código de ejemplo (requiere selenium y un driver apropiado):\n",
    "try:\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    # Ajusta path del chromedriver si es necesario\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    images = []\n",
    "    tmp_dir = tempfile.mkdtemp()\n",
    "    for mth in months:\n",
    "        # construir un mapa estático por mes (heatmap con peso solo ese mes)\n",
    "        sub = map_df[map_df['MES_STR']==mth]\n",
    "        mf = folium.Map(location=[mid_lat, mid_lon], zoom_start=6)\n",
    "        HeatMap(sub[['LATITUD','LONGITUD','INTENSIDAD_GLOB']].values.tolist(), radius=25, max_zoom=13).add_to(mf)\n",
    "        fn = os.path.join(tmp_dir, f'map_{mth}.html')\n",
    "        outpng = os.path.join(OUTPUT_DIR, f'map_{mth}.png')\n",
    "        mf.save(fn)\n",
    "        driver.set_window_size(1200, 800)\n",
    "        driver.get('file://' + os.path.abspath(fn))\n",
    "        # esperar un poco si tu máquina es lenta\n",
    "        driver.implicitly_wait(1)\n",
    "        driver.save_screenshot(outpng)\n",
    "        images.append(imageio.imread(outpng))\n",
    "    driver.quit()\n",
    "    gif_path = os.path.join(OUTPUT_DIR, 'timelapse_maps.gif')\n",
    "    imageio.mimsave(gif_path, images, duration=0.7)\n",
    "    print('GIF guardado en:', gif_path)\n",
    "except Exception as e:\n",
    "    print('No se generó GIF automáticamente. Error o falta selenium/chromedriver:', e)\n",
    "    print('Alternativa: abrir', map_html_path, 'y usar una herramienta para grabar o exportar frames manually')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
